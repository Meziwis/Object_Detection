{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection\n",
    "\n",
    "## Demo - Utilizaremos un famoso algoritmo llamado YOLO para realizar reconocimiento de objetos en tiempo real en video. \n",
    "\n",
    "### Un poco de historia de \"Object Detection\" (2001-2017)\n",
    "\n",
    "#### El primer detector de rostros eficiente (Viola-Jones Algorithm, 2001)\n",
    "\n",
    "- Un algoritmo eficiente para detección de rostros fue investado por Paul Viola & Michael Jones \n",
    "- Su demo mostraba sus rostros siendo detectados en tiempo real a traves de una webcam.\n",
    "- Fue la demostracion de vision computarizada y su potencial mas sorprendete de la epoca. \n",
    "- Luego fue implementado en OpenCV y detección de rostros se convirtió en sinonimo del algoritmo \"Viola and Jones\".\n",
    "\n",
    "![alt text](https://ars.els-cdn.com/content/image/1-s2.0-S2468067216300116-gr1.jpg \"Logo Title Text 1\")\n",
    "\n",
    "##### Una tecnica mucho más eficiente (Histograms of Oriented Gradients, 2005)\n",
    "\n",
    "- Navneet Dalal y Bill Triggs inventaron \"HOG\" para detección de transeuntes\n",
    "- Su descriptor de características, Histograms of Oriented Gradients (HOG), sobrepasó significantemente los algoritmos existentes\n",
    "  en dicha tarea.\n",
    "- Características escritas a mano, tal como antes\n",
    "- Para cada pixel, queremos ver a los pixeles directamente al rededor de él\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1440/1*RZS05e_5XXQdofdRx1GvPA.gif)\n",
    "\n",
    "- La meta es, que tan oscuro es el pixel actual en comparación con los que lo rodean\n",
    "- Luego dibujaremos una flecha mostrando la dirección en la que la imagen se vuelve más oscura:\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1440/1*WF54tQnH1Hgpoqk-Vtf9Lg.gif)\n",
    "\n",
    "- Repetimos el proceso para cada pixel de la imagen\n",
    "- cada pixel es reemplazado por una flecha, las cuales son llamadas gradientes\n",
    "- Las gradientes muestran el flujo desde luz a oscuridad a lo largo de la imagen:\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1440/1*oTdaElx_M-_z9c_iAwwqcw.gif)\n",
    "\n",
    "- Romperemos la imagen en pequeños cuadrados de 16x16 cada uno.\n",
    "- En cada cuadrado, contaremos cuantas gradientes apuntan en cada dirección\n",
    "- Luego reemplazamos ese cuadrado en la imagen con las flechas de dirección que fueron más fuertes.\n",
    "- El resultado final? La imagen original convertida en una simple representación que captura la estructura básica de la cara\n",
    "  de una forma simple:\n",
    "- Detectar rostros significa encontrar la parte de la imagen más similar a un patron HOG que fue extraido del dataset:\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1440/1*6xgev0r-qn4oR88FrW6fiA.png)\n",
    "\n",
    "#### La era del Deep Learning comienza (2012)\n",
    "\n",
    "- Convolutional Neural Networks se volvieron un estadar dorado para clasificación de imagenes luego del desempeño de la CNN de Kriszhevsky\n",
    "    durante ImageNet\n",
    "\n",
    "![Alt Text](https://image.slidesharecdn.com/cnn-toupload-final-151117124948-lva1-app6892/95/convolutional-neural-networks-cnn-65-638.jpg?cb=1455889178)\n",
    "\n",
    "Aunque los resultados son increibles, el reconocimiento de imagenes esta lejos de de la complejidad y diversidad del endendimiento\n",
    "del ojo humano.\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*bGTawFxQwzc5yV1_szDrwQ.png)\n",
    "\n",
    "En clasificación, generalmente hay una imagen con un objeto enfocado en el cual se centra la tarea de reconocer.\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*8GVucX9yhnL21KCtcyFDRQ.png)\n",
    "\n",
    "Pero cuando miramos al mundo, nosotros realizamos una tarea mucho más compleja\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*NdwfHMrW3rpj5SW_VQtWVw.png)\n",
    "\n",
    "Vemos formas complejas con muchos objetos superponiendose, diferentes fondos y no solo eso, tambien similitudes, difetencias correlaciones, etc.\n",
    "\n",
    "Pueden las CNNs ayudarnos en estas tareas tan complejas? Si.\n",
    "\n",
    "![Alt Text](https://irenelizihui.files.wordpress.com/2016/02/cnn2.png)\n",
    "\n",
    "![Alt Text](https://www.pyimagesearch.com/wp-content/uploads/2017/03/imagenet_vgg16.png)\n",
    "\n",
    "- Podemos tomar un clasificador como VGGNet o Inception y convertirlo en un detecor de objetos al mover una pequeña ventana a lo largo de la imagen\n",
    "- En cada paso ejecutas el clasificador para obtener una predicción de que tipo de objetos estan en la ventana actual. \n",
    "- Usar una ventana movil resulta en cientos de miles de predicciones por imagen, pero solo mantiene las que estan seguros.\n",
    "- Este enfoque funciona pero es muy lento, ya que debe correr el clasificador muchas veces.\n",
    "\n",
    "##### Un mejor enfoque, R-CNN\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*ZQ03Ib84bYioFKoho5HnKg.png)\n",
    "\n",
    "- R-CNN crean cuadros delimitadores, o regiones propuestas, usando un proceso llamado busqueda selectiva (Selectiva Search) \n",
    "- En un alto nivel, Selective Search ve a través de ventanas de distintos tamaños, y para cada tamaño intenta agrupar pixeles por textura, color o  intensidad, para definir los objetos.\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/0*Sdj6sKDRQyZpO6oH.)\n",
    "\n",
    "1. Genera un set de propuestas para cuadros delimitadores.\n",
    "2. Corre las imagenes en los cuadros delimitadores a través de la AlexNet y SVM pre-entrenada para saber que imagen esta en la caja.\n",
    "3. Corre los cuadros a través de una regresion lineal para obtener cajas más precisas una vés que el objeto esta clasificado.\n",
    " \n",
    "###### Algunas mejoras a las R-CNN\n",
    "R-CNN: https://arxiv.org/abs/1311.2524\n",
    "Fast R-CNN: https://arxiv.org/abs/1504.08083\n",
    "Faster R-CNN: https://arxiv.org/abs/1506.01497\n",
    "Mask R-CNN: https://arxiv.org/abs/1703.06870\n",
    "\n",
    "Pero YOLO toma otro enfoque\n",
    "\n",
    "### Qué es YOLO?\n",
    "\n",
    "- YOLO toma un enfoque completamente diferente. \n",
    "- No es un clasificador tradicional que se usó como detector de objetos. \n",
    "- YOLO mira la imagen una sola vez (lo que le da su numbre: You Only Look Once) pero de una forma inteligente.\n",
    "\n",
    "YOLO divide la imgen en una malla de 13x13 celdas:\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Grid@2x.png)\n",
    "\n",
    "- Cada celda es responsable de predecir 5 cuadros delimitadores. \n",
    "- Un cuadro delimitador describe un rectangulo que encierra un objeto.\n",
    "- YOLO tambien nos da un puntaje de confianza el cual nos dice que tan seguro está de que el cuadro delimitador encierre el objeto.\n",
    "- El puntaje no dice nada sobre que tipo de objeto hay en la caja, solo si la forma del rectangulo sirve.\n",
    "\n",
    "Los cuadros delimitadores predichos pueden verse algo como lo siguiente (mientras mayor el indice de confianza, más gorda es la linea dibujada):\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Boxes@2x.png)\n",
    "\n",
    "- Para cada cuadro delimitador, la celda tambien predice una clase. \n",
    "- Esta parte es tal como un clasificador: da un distribución de probabilidad para todas las posibles clases. \n",
    "- YOLO fue entrenado en el dataset PASCAL VOC, el cual puede detectar 20 clases difetentes como pueden ser:\n",
    "\n",
    "- bicicletas\n",
    "- botes\n",
    "- autos\n",
    "- gatos\n",
    "- perros\n",
    "- personas\n",
    "\n",
    "- El puntaje de confianza para el cuadro delimitador y la predición de clase son combinadas en un puntaje final, el cual nos dice la probabilidad de que ese cuadro delimitador contenga un objeto específico. \n",
    "- Por ejemplo, la caja amarilla nos dice que es un 85% seguro que contenga un \"perro\":\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Scores@2x.png)\n",
    "\n",
    "- Como son celdas de 13×13 = 169 celdasy cada celda precide 5 cuadros delimitadores, terminamos con 845 cuadros en total. \n",
    "- Resulta que la mayoría de esos cuadros tienen indices de confianza muy bajos, asi que nosotros solo mantenemos los cuadros cuyo puntaje final sea 30% o más(uno puede cambiar este valor dependiendo que tan preciso quiere que sea).\n",
    "\n",
    "Y la predicción final queda así:\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Prediction@2x.png)\n",
    "\n",
    "- De un total de 845 cuadros solo mantenemos 3 que nos dan los mejores resultados. \n",
    "- Pero tengan en cuanta que las 845 predicciones separadas por cuadro fueron realizadas al mismo tiempo, por lo que la red neuronal fue ejecutada solo una vez. Y eso es por lo que YOLO es tan rapido y poderoso.\n",
    "\n",
    "La arquitectura de YOLO es simple, consta solo de una \"convolutional neural network\":\n",
    "\n",
    "![Alt Text](https://i.imgur.com/QH0CvRN.png)\n",
    "\n",
    "Esta red neuronal solo usa capas estandar de los tipos: convolución con un kernel de 3x3 y pooling mazimo con kernel de 2x2. Nada muy elegante. No hay capas de tipo fully-conected en YOLOV2.\n",
    "\n",
    "La ultima capa convulocional tiene un kernel de 1x1 y existe para reducir los datos a una forma de 13x13x125. Esta 13x13 deberia ser familiar: ya que es la malla en la que fue dividida la imagen.\n",
    "\n",
    "Entonces terminamos con 125 canales por cada malla de celdas. Estos 125 numeros contienen los datos para los cuadros delimitadores y las predicciones de clase. Por qué 125? Para cada malla de celdas se predicen 5 cuadros delimitadores y estos se describen por 25 elementos:\n",
    "\n",
    "- x, y, ancho, alto para el rectangulo del cuadro delimitador\n",
    "- el puntaje de confianza\n",
    "- la distribución de probabilidad entre las clases\n",
    "\n",
    "Usar YOLO es simple: le das una imagen ded entrada (debe ser escalada a 416x146 pixeles), pasa a través de la \"convolutional network\" de una sola ves, y sale del otro lado como un tensor de 13x13x125 el que describe los cuadros delimitadores para las mallas de celdas. Todo lo que necesitas hacer es calcular los puntajes finales para cada cuadro e ignorar los menores al 30%.\n",
    "\n",
    "### Mejoras a YOLO v1\n",
    "\n",
    "YoLO v2 vs YoLO v1\n",
    "\n",
    "- Velocidad (45 cuadros por segundo)\n",
    "- Redes entienden representaciones generalizadas (Lo cual permite entrenar en imagenes reales, y al momento de predecir arte se obtuvo resultados bastante precisos).\n",
    "- Versión rápida (con arquitectura más pequeña) — 155 cuadros por segundo, pero más impresiso.\n",
    "\n",
    "Paper aquí\n",
    "https://arxiv.org/pdf/1612.08242v1.pdf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
